\section{Introduction}
\textit{Clustering} is one of the main techniques within data mining. This technique is a descriptive method that tries to discover unknown patterns within a data set, by partitioning the data objects into \textit{clusters}. Here, each object in a cluster is similar to one another, but different from objects in other clusters. Clustering is widely used in many applications, such as advertising, biology, web search and business intelligence \cite[p.~444]{han-2011}.

The task of clustering data is a challenging task, first, the data sets are typical large in size, which means that the clustering algorithm must be \textit{scalable}. Additionally, data sets often contains numerous features (\textit{attributes}), which introduces the problem of \textit{curse of dimensionality}, which refers to a several challenges related to high-dimensional data spaces:

First, the issue of \textit{concentration of distances}, where distances between objects in high-dimensional spaces become increasingly similar as dimensionality increases. This means that data points tend to become nearly equidistant from one another, making it difficult for traditional distance-based algorithms to discover clusters.

Secondly, there is the problem of \textit{local feature relevance} and \textit{local feature correlation}, where only a subset of features or different combinations of feature correlations may be relevant for clustering. Consequently, feature reduction techniques like \textit{Principal Component Analysis (PCA)}, which project the original space onto a lower-dimensional subspace, are inadequate because they typically identify only one global subspace that best fits the entire dataset. Also, algorithms that evaluate the entire feature space does not address this issue effectively. \cite[p.~43--46]{kriegel-2009}

Instead of relying on a global approach to feature selection, a local approach that addresses the issues of local feature relevance and local feature correlation is necessary. However, we then need to deal with two separate problems, which both needs to be solved simultaneously. First, is the problem of finding the relevant subspaces of each cluster. Second, is the problem of finding the clusters in each relevant subspace. To solve them efficiently, heuristics needs to be employed into the clustering algorithms. \cite[p.~6--7]{kriegel-2009}

For many applications, it is reasonable to focus only on clusters in axis-parallel subspaces, thus restricting the search space to $O(2^d)$ dimensions. These algorithms are called \textit{subspace clustering} (or \textit{projected clustering}) algorithms. These can be further divided into: \textit{top-down}- or \textit{bottom-up} approach. In top-down approach, the relevant subspaces for the clusters are determined by gradually reducing the subspaces, starting from the entire space. In contrast, bottom-up approaches, finds the relevant subspaces for the clusters from the original space starting from 1-dimensional using the \textit{monotonicity property} (or \textit{downward closure property}), see Lemma \ref{lem:mono} \cite{clique}. \cite[p.~8,~11]{kriegel-2009}

For the rest of this paper, the following notation will be adopted: Let $\mathcal{A} = \{A_1, \dots, A_d\}$ be a set of attributes, and $\mathcal{S} = A_1 \times A_2 \times \dots A_d$ a $d$-dimensional numerical space containing $n$ points $p_1, \dots, p_n$. Let $A_1, \dots, A_d$ be the dimensions (attributes) of $\mathcal{S}$.

\begin{lemma}\label{lem:mono}
    If a collection of points $C$ is a cluster in a $k$-dimensional subspace, then $C$ is also part of a cluster in any $(k-1)$-dimensional projection of this space.
\end{lemma}

\subsection{Contributions}
The primary focus of this paper is to analyze the bottom-up subspace clustering algorithm \textit{MAFIA} \cite{mafia}, which builds upon the pioneering subspace clustering algorithm \textit{CLIQUE} \cite{clique}. This paper examines the relationship between these two grid-based algorithms, highlighting their similarities and differences. Additionally, the density-connectivity-based algorithm \textit{SUBCLU} \cite{subclu} is included for analysis and evaluation, as it offers a contrasting approach to grid-based methods.

The remainder of the paper is structured as follows: Section 2 describes and analyzes the three algorithms in detail. Section 3 evaluates their performance in terms of scalability, considering dataset size, data- and cluster-dimensionality, as well as their clustering quality. Section 5 discusses the findings and explores the contributions of each algorithm to the field of subspace clustering. Finally, Section 6 concludes the main findings and suggests some future work.