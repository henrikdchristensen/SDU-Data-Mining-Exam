\section{Discussion}
\begin{itemize}
    \item Discussion of the different approaches
    \item Discussion of results
    \item Limitations and Strengths
    \item Model: Input parameters; Assumptions on number, size, and shape of clusters; Noise
    \item Determinism
    \item Independence w.r.t. order of objects/attributes
    \item Assumptions on overlap/non-overlap of clusters/subspaces
    \item Effiency
\end{itemize}


Interpretability and usability: Clustering results should be easy to interpret and algorithms should produce clusters that are meaningful and comprehensible, making the results practical for decision-making.

Discovery of arbitrary-shaped clusters: Many clustering algorithms are limited to detecting spherical clusters based on distance measures (e.g. Euclidean distance). However, clusters in real-world data often take arbitrary shapes.

Minimize dependence on domain knowledge: Many clustering algorithms require users to provide specific input parameters, such as the number of clusters, which can be challenging to determine a prior. Reducing such parameters not only simplifies the process for users but also improve the reliability of the results.

Robust to noisy data: Real-world data is often noisy or contains outliers, which can distort clustering results. Clustering algorithms should be robust enough to handle noisy data, missing values, and outliers without degrading the quality of the clusters.

\cite[p.~446-447]{han-2011}