# SDU-Data-Mining-Exam

Two different data generator programs are used to generate clustered datasets.

"MDCGEN" (https://link.springer.com/article/10.1007/s00357-019-9312-3) which is very efficient for large scale high-dimensional data and "Artifical Cluster" (https://doi.org/10.36227/techrxiv.19091330.v1) which is more flexible in terms of cluster shapes. It should be noticed that I have no success in generating datasets >1 mio. data points using "Artifical Cluster", so for large scale data, "MDCGEN" is the way to go, that why most of the datasets are generated using "MDCGEN".


## MDCGEN
Download `mdcgen-matlab` from https://github.com/CN-TU/mdcgen-matlab and unzip it. Place the content of the unzipped folder in a folder in root called `mdcgen`. You can remove all the files and folders except from `mdcgen` and `config_build`. But do also keep `mdc_help.m`.

The folder structure should look like this:
```bash
.
├── mdcgen
│   ├── mdcgen
│   │   ├── ...
│   ├── config_build
│   │   ├── ...
│   ├── mdc_help.m
```

The version used for the development of this project is from the commit "9b201f9" (from Sep 16, 2019).

A written extension script called `mdcgen_script.m` is used to save datasets with labels into an .csv file incl. plotting the data.

This extension script program loads a config file from `datasets/mdcgen/<dataset>` and generates a dataset based on the config file.

Did not have any success in generating datasets >4 mio. data points using on my local machine with 16GB RAM. Instead, I have used the MATLAB Online service to generate the large datasets.

If defining nNoise manually in terms of which clusters has which dims as noise, where each column correspond to a cluster and where the rows defines which dims that are noise for that cluster, then please make sure it has at least 2 dims (rows) defined as noise - if only one dim is noise just insert the same dim in the 2nd row. Example 3 dims and 2 clusters, where for the first cluster the 3rd dim is noise and for the second cluster the 1st dim is noise:
```matlab
nNoise = [3,1;3,1];
```

## Artifical Cluster
Download `artificalCluster-1.0.jar` file from https://github.com/wk1lian/ArtificalCluster and place it in the `data-generator` directory.

The version used for the development of this project is from the commit "27d7586" (Jan 19, 2024).

To generate a dataset based on a config file from the `datasets/artificalCluster` folder, we can, for example, run the following command from the `data-generator` directory:
```bash
java -jar artificalCluster-1.0.jar -rg="datasets/artificalCluster/bez/bez.config" -o="datasets/artificalCluster/bez/bez.txt" && python helpers/fix_labels.py datasets/artificalCluster/bez/bez.txt -l -n 0.1
```

Here the `-n` flag is used to add noise to the dataset. The value is the percentage of noise to add (0.1 = 10% noise). The `-l` flag is used to add labels to the dataset.

## Helper scripts

### count_datapoints.py
This script is used to count the number of data points in a dataset. From the `data-generator` directory, run, for example, the following command:
```bash
python helpers/count_datapoints.py datasets/artificalCluster/bez/bez.txt
```

### fix_labels.py
This script is used fixed the labels generated by the `Artifical Cluster` program. See under [Artifical Cluster](#artifical-cluster) for more information.

## .gitignore
All datasets are ignored by git except from config files. This is to avoid committing large files to the repository.

## GPUMAFIA
Verbose output is disabled by default. To enable verbose output, use the flag `-V`.

First note that GPUMAFIA is 0-indexed, so the first cluster is index 0 same goes for the dimensions.

This will output each dimension's histogram values. Next, it shows the merged windows sizes for each dimension. Next, the DUs are shown for each dimension. Finally, the clusters are shown with the corresponding DUs. The notation "cluster 2 (4): [ [0:0.30..0.60 6:0.00..0.20 7:0.75..1.00 8:0.10..0.40] ]", means that cluster 2 is 4-dimensional defined by the dimensions 0, 6, 7, and 8. The values in the brackets are the DUs for each dimension.

## ELKI
plot png 8.000x8.000 pixels.

# Conda
```bash
conda env create -n mining
```

```bash
conda activate mining
```

## Pip
```bash
pip install -r requirements.txt
```